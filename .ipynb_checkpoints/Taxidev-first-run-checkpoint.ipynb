{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cb81a5b-facd-4fed-8de7-381e623acb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azureml-dataset-runtime in c:\\users\\megan\\anaconda3\\lib\\site-packages (1.56.0)\n",
      "Requirement already satisfied: azureml-dataprep<5.2.0a,>=5.1.0a in c:\\users\\megan\\anaconda3\\lib\\site-packages (from azureml-dataset-runtime) (5.1.6)\n",
      "Requirement already satisfied: pyarrow>=0.17.0 in c:\\users\\megan\\anaconda3\\lib\\site-packages (from azureml-dataset-runtime) (14.0.2)\n",
      "Requirement already satisfied: numpy!=1.19.4,<1.24 in c:\\users\\megan\\anaconda3\\lib\\site-packages (from azureml-dataset-runtime) (1.23.5)\n",
      "Requirement already satisfied: azureml-dataprep-native<42.0.0,>=41.0.0 in c:\\users\\megan\\anaconda3\\lib\\site-packages (from azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime) (41.0.0)\n",
      "Requirement already satisfied: azureml-dataprep-rslex~=2.22.2dev0 in c:\\users\\megan\\anaconda3\\lib\\site-packages (from azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime) (2.22.2)\n",
      "Requirement already satisfied: cloudpickle<3.0.0,>=1.1.0 in c:\\users\\megan\\anaconda3\\lib\\site-packages (from azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime) (2.2.1)\n",
      "Requirement already satisfied: azure-identity>=1.7.0 in c:\\users\\megan\\anaconda3\\lib\\site-packages (from azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime) (1.17.1)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\megan\\anaconda3\\lib\\site-packages (from azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime) (4.19.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.1.0 in c:\\users\\megan\\anaconda3\\lib\\site-packages (from azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime) (6.0.1)\n",
      "Requirement already satisfied: azure-core>=1.23.0 in c:\\users\\megan\\anaconda3\\lib\\site-packages (from azure-identity>=1.7.0->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime) (1.30.2)\n",
      "Requirement already satisfied: cryptography>=2.5 in c:\\users\\megan\\anaconda3\\lib\\site-packages (from azure-identity>=1.7.0->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime) (42.0.2)\n",
      "Requirement already satisfied: msal>=1.24.0 in c:\\users\\megan\\anaconda3\\lib\\site-packages (from azure-identity>=1.7.0->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime) (1.29.0)\n",
      "Requirement already satisfied: msal-extensions>=0.3.0 in c:\\users\\megan\\anaconda3\\lib\\site-packages (from azure-identity>=1.7.0->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\megan\\anaconda3\\lib\\site-packages (from azure-identity>=1.7.0->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime) (4.9.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\megan\\anaconda3\\lib\\site-packages (from jsonschema->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\megan\\anaconda3\\lib\\site-packages (from jsonschema->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\megan\\anaconda3\\lib\\site-packages (from jsonschema->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\megan\\anaconda3\\lib\\site-packages (from jsonschema->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime) (0.10.6)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\users\\megan\\anaconda3\\lib\\site-packages (from azure-core>=1.23.0->azure-identity>=1.7.0->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\megan\\anaconda3\\lib\\site-packages (from azure-core>=1.23.0->azure-identity>=1.7.0->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\megan\\anaconda3\\lib\\site-packages (from cryptography>=2.5->azure-identity>=1.7.0->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime) (1.16.0)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in c:\\users\\megan\\anaconda3\\lib\\site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.24.0->azure-identity>=1.7.0->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime) (2.4.0)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in c:\\users\\megan\\anaconda3\\lib\\site-packages (from msal-extensions>=0.3.0->azure-identity>=1.7.0->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime) (2.10.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\megan\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity>=1.7.0->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime) (2.21)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\megan\\anaconda3\\lib\\site-packages (from portalocker<3,>=1.4->msal-extensions>=0.3.0->azure-identity>=1.7.0->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime) (305.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\megan\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-identity>=1.7.0->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\megan\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-identity>=1.7.0->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\megan\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-identity>=1.7.0->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\megan\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-identity>=1.7.0->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime) (2024.6.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install azureml-dataset-runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17d4737a-d91b-45e5-8154-7aaaf536d3ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "incomplete escape \\U at position 28",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#%conda env list\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconda\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124menv list\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2456\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2454\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2455\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2456\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2458\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[0;32m   2459\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[0;32m   2460\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[0;32m   2461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\magics\\packaging.py:30\u001b[0m, in \u001b[0;36mis_conda_environment.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Path(sys\u001b[38;5;241m.\u001b[39mprefix, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconda-meta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe python kernel does not appear to be a conda environment.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use ``\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mpip install`` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m     )\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\magics\\packaging.py:128\u001b[0m, in \u001b[0;36mPackagingMagics.conda\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;129m@line_magic\u001b[39m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;129m@is_conda_environment\u001b[39m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconda\u001b[39m(\u001b[38;5;28mself\u001b[39m, line):\n\u001b[0;32m    123\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run the conda package manager within the current kernel.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03m    Usage:\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;124;03m      %conda install [pkgs]\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m     conda \u001b[38;5;241m=\u001b[39m _get_conda_like_executable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_command(conda, line)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\magics\\packaging.py:53\u001b[0m, in \u001b[0;36m_get_conda_like_executable\u001b[1;34m(command)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Otherwise, attempt to extract the executable from conda history.\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# This applies in any conda environment.\u001b[39;00m\n\u001b[0;32m     52\u001b[0m history \u001b[38;5;241m=\u001b[39m Path(sys\u001b[38;5;241m.\u001b[39mprefix, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconda-meta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mread_text(encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 53\u001b[0m match \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^#\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*cmd:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*(?P<command>.*\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecutable\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms[create|install]\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     55\u001b[0m     history,\n\u001b[0;32m     56\u001b[0m     flags\u001b[38;5;241m=\u001b[39mre\u001b[38;5;241m.\u001b[39mMULTILINE,\n\u001b[0;32m     57\u001b[0m )\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m match:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m match\u001b[38;5;241m.\u001b[39mgroupdict()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommand\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\__init__.py:176\u001b[0m, in \u001b[0;36msearch\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    174\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Scan through string looking for a match to the pattern, returning\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;124;03m    a Match object, or None if no match was found.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _compile(pattern, flags)\u001b[38;5;241m.\u001b[39msearch(string)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\__init__.py:294\u001b[0m, in \u001b[0;36m_compile\u001b[1;34m(pattern, flags)\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m    289\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe re.TEMPLATE/re.T flag is deprecated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    290\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is an undocumented flag \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    291\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout an obvious purpose. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    292\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDon\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt use it.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    293\u001b[0m               \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m--> 294\u001b[0m p \u001b[38;5;241m=\u001b[39m _compiler\u001b[38;5;241m.\u001b[39mcompile(pattern, flags)\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (flags \u001b[38;5;241m&\u001b[39m DEBUG):\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_cache) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m _MAXCACHE:\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;66;03m# Drop the oldest item\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\_compiler.py:745\u001b[0m, in \u001b[0;36mcompile\u001b[1;34m(p, flags)\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isstring(p):\n\u001b[0;32m    744\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m p\n\u001b[1;32m--> 745\u001b[0m     p \u001b[38;5;241m=\u001b[39m _parser\u001b[38;5;241m.\u001b[39mparse(p, flags)\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    747\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\_parser.py:989\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(str, flags, state)\u001b[0m\n\u001b[0;32m    986\u001b[0m state\u001b[38;5;241m.\u001b[39mflags \u001b[38;5;241m=\u001b[39m flags\n\u001b[0;32m    987\u001b[0m state\u001b[38;5;241m.\u001b[39mstr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m\n\u001b[1;32m--> 989\u001b[0m p \u001b[38;5;241m=\u001b[39m _parse_sub(source, state, flags \u001b[38;5;241m&\u001b[39m SRE_FLAG_VERBOSE, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    990\u001b[0m p\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mflags \u001b[38;5;241m=\u001b[39m fix_flags(\u001b[38;5;28mstr\u001b[39m, p\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mflags)\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source\u001b[38;5;241m.\u001b[39mnext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\_parser.py:464\u001b[0m, in \u001b[0;36m_parse_sub\u001b[1;34m(source, state, verbose, nested)\u001b[0m\n\u001b[0;32m    462\u001b[0m start \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 464\u001b[0m     itemsappend(_parse(source, state, verbose, nested \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    465\u001b[0m                        \u001b[38;5;129;01mnot\u001b[39;00m nested \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m items))\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sourcematch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    467\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\_parser.py:872\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[0;32m    869\u001b[0m     group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    870\u001b[0m sub_verbose \u001b[38;5;241m=\u001b[39m ((verbose \u001b[38;5;129;01mor\u001b[39;00m (add_flags \u001b[38;5;241m&\u001b[39m SRE_FLAG_VERBOSE)) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    871\u001b[0m                \u001b[38;5;129;01mnot\u001b[39;00m (del_flags \u001b[38;5;241m&\u001b[39m SRE_FLAG_VERBOSE))\n\u001b[1;32m--> 872\u001b[0m p \u001b[38;5;241m=\u001b[39m _parse_sub(source, state, sub_verbose, nested \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    873\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m source\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    874\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m source\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing ), unterminated subpattern\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    875\u001b[0m                        source\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;241m-\u001b[39m start)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\_parser.py:464\u001b[0m, in \u001b[0;36m_parse_sub\u001b[1;34m(source, state, verbose, nested)\u001b[0m\n\u001b[0;32m    462\u001b[0m start \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 464\u001b[0m     itemsappend(_parse(source, state, verbose, nested \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    465\u001b[0m                        \u001b[38;5;129;01mnot\u001b[39;00m nested \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m items))\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sourcematch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    467\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\_parser.py:548\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m this[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 548\u001b[0m     code \u001b[38;5;241m=\u001b[39m _escape(source, this, state)\n\u001b[0;32m    549\u001b[0m     subpatternappend(code)\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m this \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SPECIAL_CHARS:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\_parser.py:402\u001b[0m, in \u001b[0;36m_escape\u001b[1;34m(source, escape, state)\u001b[0m\n\u001b[0;32m    400\u001b[0m escape \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mgetwhile(\u001b[38;5;241m8\u001b[39m, HEXDIGITS)\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(escape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m10\u001b[39m:\n\u001b[1;32m--> 402\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m source\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincomplete escape \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m escape, \u001b[38;5;28mlen\u001b[39m(escape))\n\u001b[0;32m    403\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(escape[\u001b[38;5;241m2\u001b[39m:], \u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28mchr\u001b[39m(c) \u001b[38;5;66;03m# raise ValueError for invalid code\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: incomplete escape \\U at position 28"
     ]
    }
   ],
   "source": [
    "#%conda env list\n",
    "%conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e2f7ba1-d8f5-417c-affc-b661273ba702",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Megan\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated and will be removed in a future release\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'infer_column_types': 'False', 'activity': 'download'}\n",
      "{'infer_column_types': 'False', 'activity': 'download', 'activityApp': 'FileDataset'}\n",
      "[Info] read from C:\\Users\\Megan\\AppData\\Local\\Temp\\tmprxww5eia\\https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/green/puYear=2018/puMonth=5/part-00087-tid-4753095944193949832-fee7e113-666d-4114-9fcb-bcd3046479f3-2657-1.c000.snappy.parquet\n",
      "[Info] read from C:\\Users\\Megan\\AppData\\Local\\Temp\\tmprxww5eia\\https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/green/puYear=2018/puMonth=6/part-00171-tid-4753095944193949832-fee7e113-666d-4114-9fcb-bcd3046479f3-2741-1.c000.snappy.parquet\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 923257 entries, 0 to 598725\n",
      "Data columns (total 23 columns):\n",
      " #   Column                Non-Null Count   Dtype         \n",
      "---  ------                --------------   -----         \n",
      " 0   vendorID              923257 non-null  int32         \n",
      " 1   lpepPickupDatetime    923257 non-null  datetime64[ns]\n",
      " 2   lpepDropoffDatetime   923257 non-null  datetime64[ns]\n",
      " 3   passengerCount        923257 non-null  int32         \n",
      " 4   tripDistance          923257 non-null  float64       \n",
      " 5   puLocationId          923257 non-null  object        \n",
      " 6   doLocationId          923257 non-null  object        \n",
      " 7   pickupLongitude       0 non-null       float64       \n",
      " 8   pickupLatitude        0 non-null       float64       \n",
      " 9   dropoffLongitude      0 non-null       float64       \n",
      " 10  dropoffLatitude       0 non-null       float64       \n",
      " 11  rateCodeID            923257 non-null  int32         \n",
      " 12  storeAndFwdFlag       923257 non-null  object        \n",
      " 13  paymentType           923257 non-null  int32         \n",
      " 14  fareAmount            923257 non-null  float64       \n",
      " 15  extra                 923257 non-null  float64       \n",
      " 16  mtaTax                923257 non-null  float64       \n",
      " 17  improvementSurcharge  923257 non-null  object        \n",
      " 18  tipAmount             923257 non-null  float64       \n",
      " 19  tollsAmount           923257 non-null  float64       \n",
      " 20  ehailFee              0 non-null       float64       \n",
      " 21  totalAmount           923257 non-null  float64       \n",
      " 22  tripType              923257 non-null  int32         \n",
      "dtypes: datetime64[ns](2), float64(12), int32(5), object(4)\n",
      "memory usage: 151.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# This is a package in preview.\n",
    "from azureml.opendatasets import NycTlcGreen\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "end_date = parser.parse('2018-06-06')\n",
    "start_date = parser.parse('2018-05-01')\n",
    "nyc_tlc = NycTlcGreen(start_date=start_date, end_date=end_date)\n",
    "nyc_tlc_df = nyc_tlc.to_pandas_dataframe()\n",
    "\n",
    "nyc_tlc_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9a67667-9629-4b60-ae27-a20db9575886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'infer_column_types': 'False', 'activity': 'download'}\n",
      "{'infer_column_types': 'False', 'activity': 'download', 'activityApp': 'FileDataset'}\n",
      "An error occurred: UserErrorException:\n",
      "\tMessage: Execution failed with error message: The requested stream was not found. Please make sure the request uri is correct.| session_id=20d910f2-02c8-424e-aa33-546604738fed ErrorCode: ScriptExecution.StreamAccess.NotFound\n",
      "\tInnerException \n",
      "Error Code: ScriptExecution.StreamAccess.NotFound\n",
      "Native Error: Dataflow visit error: ExecutionError(StreamError(NotFound))\n",
      "\tVisitError(ExecutionError(StreamError(NotFound)))\n",
      "=> Failed with execution error: error in streaming from input data sources\n",
      "\tExecutionError(StreamError(NotFound))\n",
      "Error Message: The requested stream was not found. Please make sure the request uri is correct.| session_id=20d910f2-02c8-424e-aa33-546604738fed\n",
      "\tErrorResponse \n",
      "{\n",
      "    \"error\": {\n",
      "        \"code\": \"UserError\",\n",
      "        \"message\": \"Execution failed with error message: The requested stream was not found. Please make sure the request uri is correct.| session_id=20d910f2-02c8-424e-aa33-546604738fed ErrorCode: ScriptExecution.StreamAccess.NotFound\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# This is a package in preview.\n",
    "from azureml.opendatasets import NycTlcGreen\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "import pandas as pd\n",
    "\n",
    "# Define the date range\n",
    "end_date = parser.parse('2022-01-15')\n",
    "start_date = parser.parse('2022-01-01')\n",
    "\n",
    "try:\n",
    "    # Load the dataset\n",
    "    nyc_tlc = NycTlcGreen(start_date=start_date, end_date=end_date)\n",
    "    nyc_tlc_df = nyc_tlc.to_pandas_dataframe()\n",
    "    \n",
    "    # Display basic information about the dataframe\n",
    "    nyc_tlc_df.info()\n",
    "\n",
    "    # Filter data for the specific date range\n",
    "    filtered_df = nyc_tlc_df[(nyc_tlc_df['lpep_pickup_datetime'] >= start_date) & (nyc_tlc_df['lpep_pickup_datetime'] < end_date + pd.Timedelta(days=1))]\n",
    "\n",
    "    # Show the number of rides\n",
    "    num_rides = len(filtered_df)\n",
    "    print(f\"Number of rides from January 1, 2022, to January 15, 2022: {num_rides}\")\n",
    "\n",
    "    # Display the filtered data\n",
    "    filtered_df.head()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55ae790d-b365-44f6-b450-e52bd4f677f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'infer_column_types': 'False', 'activity': 'download'}\n",
      "{'infer_column_types': 'False', 'activity': 'download', 'activityApp': 'FileDataset'}\n",
      "[Info] read from C:\\Users\\Megan\\AppData\\Local\\Temp\\tmpm9iu7ji3\\https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/green/puYear=2018/puMonth=1/part-00036-tid-4753095944193949832-fee7e113-666d-4114-9fcb-bcd3046479f3-2606-1.c000.snappy.parquet\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 348031 entries, 0 to 563192\n",
      "Data columns (total 23 columns):\n",
      " #   Column                Non-Null Count   Dtype         \n",
      "---  ------                --------------   -----         \n",
      " 0   vendorID              348031 non-null  int32         \n",
      " 1   lpepPickupDatetime    348031 non-null  datetime64[ns]\n",
      " 2   lpepDropoffDatetime   348031 non-null  datetime64[ns]\n",
      " 3   passengerCount        348031 non-null  int32         \n",
      " 4   tripDistance          348031 non-null  float64       \n",
      " 5   puLocationId          348031 non-null  object        \n",
      " 6   doLocationId          348031 non-null  object        \n",
      " 7   pickupLongitude       0 non-null       float64       \n",
      " 8   pickupLatitude        0 non-null       float64       \n",
      " 9   dropoffLongitude      0 non-null       float64       \n",
      " 10  dropoffLatitude       0 non-null       float64       \n",
      " 11  rateCodeID            348031 non-null  int32         \n",
      " 12  storeAndFwdFlag       348031 non-null  object        \n",
      " 13  paymentType           348031 non-null  int32         \n",
      " 14  fareAmount            348031 non-null  float64       \n",
      " 15  extra                 348031 non-null  float64       \n",
      " 16  mtaTax                348031 non-null  float64       \n",
      " 17  improvementSurcharge  348031 non-null  object        \n",
      " 18  tipAmount             348031 non-null  float64       \n",
      " 19  tollsAmount           348031 non-null  float64       \n",
      " 20  ehailFee              0 non-null       float64       \n",
      " 21  totalAmount           348031 non-null  float64       \n",
      " 22  tripType              348028 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(13), int32(4), object(4)\n",
      "memory usage: 58.4+ MB\n",
      "An error occurred: 'lpep_pickup_datetime'\n"
     ]
    }
   ],
   "source": [
    "# This is a package in preview.\n",
    "from azureml.opendatasets import NycTlcGreen\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "import pandas as pd\n",
    "\n",
    "# Define the date range\n",
    "end_date = parser.parse('2018-01-15')\n",
    "start_date = parser.parse('2018-01-01')\n",
    "\n",
    "try:\n",
    "    # Load the dataset\n",
    "    nyc_tlc = NycTlcGreen(start_date=start_date, end_date=end_date)\n",
    "    nyc_tlc_df = nyc_tlc.to_pandas_dataframe()\n",
    "    \n",
    "    # Display basic information about the dataframe\n",
    "    nyc_tlc_df.info()\n",
    "\n",
    "    # Filter data for the specific date range\n",
    "    filtered_df = nyc_tlc_df[(nyc_tlc_df['lpep_pickup_datetime'] >= start_date) & (nyc_tlc_df['lpep_pickup_datetime'] < end_date + pd.Timedelta(days=1))]\n",
    "\n",
    "    # Show the number of rides\n",
    "    num_rides = len(filtered_df)\n",
    "    print(f\"Number of rides from January 1, 2022, to January 15, 2022: {num_rides}\")\n",
    "\n",
    "    # Display the filtered data\n",
    "    filtered_df.head()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d724f9c-5e70-4c06-8882-954f91ccc08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'infer_column_types': 'False', 'activity': 'download'}\n",
      "{'infer_column_types': 'False', 'activity': 'download', 'activityApp': 'FileDataset'}\n",
      "[Info] read from /var/folders/m1/v2p5dlc135x8ctp72qfss6200000gn/T/tmpma3vwn0l/https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/green/puYear=2018/puMonth=1/part-00036-tid-4753095944193949832-fee7e113-666d-4114-9fcb-bcd3046479f3-2606-1.c000.snappy.parquet\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 348031 entries, 0 to 563192\n",
      "Data columns (total 23 columns):\n",
      " #   Column                Non-Null Count   Dtype         \n",
      "---  ------                --------------   -----         \n",
      " 0   vendorID              348031 non-null  int32         \n",
      " 1   lpepPickupDatetime    348031 non-null  datetime64[ns]\n",
      " 2   lpepDropoffDatetime   348031 non-null  datetime64[ns]\n",
      " 3   passengerCount        348031 non-null  int32         \n",
      " 4   tripDistance          348031 non-null  float64       \n",
      " 5   puLocationId          348031 non-null  object        \n",
      " 6   doLocationId          348031 non-null  object        \n",
      " 7   pickupLongitude       0 non-null       float64       \n",
      " 8   pickupLatitude        0 non-null       float64       \n",
      " 9   dropoffLongitude      0 non-null       float64       \n",
      " 10  dropoffLatitude       0 non-null       float64       \n",
      " 11  rateCodeID            348031 non-null  int32         \n",
      " 12  storeAndFwdFlag       348031 non-null  object        \n",
      " 13  paymentType           348031 non-null  int32         \n",
      " 14  fareAmount            348031 non-null  float64       \n",
      " 15  extra                 348031 non-null  float64       \n",
      " 16  mtaTax                348031 non-null  float64       \n",
      " 17  improvementSurcharge  348031 non-null  object        \n",
      " 18  tipAmount             348031 non-null  float64       \n",
      " 19  tollsAmount           348031 non-null  float64       \n",
      " 20  ehailFee              0 non-null       float64       \n",
      " 21  totalAmount           348031 non-null  float64       \n",
      " 22  tripType              348028 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(13), int32(4), object(4)\n",
      "memory usage: 58.4+ MB\n",
      "   vendorID  lpepPickupDatetime lpepDropoffDatetime  passengerCount  \\\n",
      "0         2 2018-01-07 19:42:46 2018-01-07 19:48:12               1   \n",
      "1         2 2018-01-08 10:48:34 2018-01-08 11:09:09               1   \n",
      "2         2 2018-01-12 19:06:16 2018-01-12 19:20:40               1   \n",
      "3         2 2018-01-12 19:25:24 2018-01-12 20:05:02               1   \n",
      "4         1 2018-01-12 19:24:58 2018-01-12 19:39:50               1   \n",
      "\n",
      "   tripDistance puLocationId doLocationId  pickupLongitude  pickupLatitude  \\\n",
      "0          0.77           42           42              NaN             NaN   \n",
      "1          2.34           74          236              NaN             NaN   \n",
      "2          1.54           82          129              NaN             NaN   \n",
      "3          6.36          129          161              NaN             NaN   \n",
      "4          1.80           75          152              NaN             NaN   \n",
      "\n",
      "   dropoffLongitude  ...  paymentType  fareAmount extra  mtaTax  \\\n",
      "0               NaN  ...            1         5.5   0.0     0.5   \n",
      "1               NaN  ...            1        14.0   0.0     0.5   \n",
      "2               NaN  ...            1        10.0   1.0     0.5   \n",
      "3               NaN  ...            2        27.0   1.0     0.5   \n",
      "4               NaN  ...            2        10.5   1.0     0.5   \n",
      "\n",
      "   improvementSurcharge  tipAmount  tollsAmount ehailFee  totalAmount  \\\n",
      "0                   0.3       1.26          0.0      NaN         7.56   \n",
      "1                   0.3       2.96          0.0      NaN        17.76   \n",
      "2                   0.3       2.36          0.0      NaN        14.16   \n",
      "3                   0.3       0.00          0.0      NaN        28.80   \n",
      "4                   0.3       0.00          0.0      NaN        12.30   \n",
      "\n",
      "   tripType  \n",
      "0       1.0  \n",
      "1       1.0  \n",
      "2       1.0  \n",
      "3       1.0  \n",
      "4       1.0  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "Columns in the dataframe: Index(['vendorID', 'lpepPickupDatetime', 'lpepDropoffDatetime',\n",
      "       'passengerCount', 'tripDistance', 'puLocationId', 'doLocationId',\n",
      "       'pickupLongitude', 'pickupLatitude', 'dropoffLongitude',\n",
      "       'dropoffLatitude', 'rateCodeID', 'storeAndFwdFlag', 'paymentType',\n",
      "       'fareAmount', 'extra', 'mtaTax', 'improvementSurcharge', 'tipAmount',\n",
      "       'tollsAmount', 'ehailFee', 'totalAmount', 'tripType'],\n",
      "      dtype='object')\n",
      "An error occurred: 'pickup_datetime'\n"
     ]
    }
   ],
   "source": [
    "# This is a package in preview.\n",
    "from azureml.opendatasets import NycTlcGreen\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "import pandas as pd\n",
    "\n",
    "# Define the date range\n",
    "end_date = parser.parse('2018-01-15')\n",
    "start_date = parser.parse('2018-01-01')\n",
    "\n",
    "try:\n",
    "    # Load the dataset\n",
    "    nyc_tlc = NycTlcGreen(start_date=start_date, end_date=end_date)\n",
    "    nyc_tlc_df = nyc_tlc.to_pandas_dataframe()\n",
    "    \n",
    "    # Display basic information about the dataframe\n",
    "    nyc_tlc_df.info()\n",
    "\n",
    "    # Print the first few rows to inspect column names\n",
    "    print(nyc_tlc_df.head())\n",
    "\n",
    "    # Check the columns in the dataframe\n",
    "    print(\"Columns in the dataframe:\", nyc_tlc_df.columns)\n",
    "\n",
    "    # Adjust the column name based on the available columns\n",
    "    pickup_column = 'lpep_pickup_datetime' if 'lpep_pickup_datetime' in nyc_tlc_df.columns else 'pickup_datetime'\n",
    "    \n",
    "    # Filter data for the specific date range\n",
    "    filtered_df = nyc_tlc_df[(nyc_tlc_df[pickup_column] >= start_date) & (nyc_tlc_df[pickup_column] < end_date + pd.Timedelta(days=1))]\n",
    "\n",
    "    # Show the number of rides\n",
    "    num_rides = len(filtered_df)\n",
    "    print(f\"Number of rides from January 1, 2018, to January 15, 2018: {num_rides}\")\n",
    "\n",
    "    # Display the filtered data\n",
    "    filtered_df.head()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e38e7b42-eb5a-4980-847c-8069863d9dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'infer_column_types': 'False', 'activity': 'download'}\n",
      "{'infer_column_types': 'False', 'activity': 'download', 'activityApp': 'FileDataset'}\n",
      "[Info] read from C:\\Users\\Megan\\AppData\\Local\\Temp\\tmplrb6of1o\\https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/green/puYear=2016/puMonth=1/part-00119-tid-4753095944193949832-fee7e113-666d-4114-9fcb-bcd3046479f3-2689-1.c000.snappy.parquet\n",
      "{'infer_column_types': 'False', 'activity': 'download'}\n",
      "{'infer_column_types': 'False', 'activity': 'download', 'activityApp': 'FileDataset'}\n",
      "[Info] read from C:\\Users\\Megan\\AppData\\Local\\Temp\\tmpfnxsg66x\\https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/green/puYear=2016/puMonth=2/part-00060-tid-4753095944193949832-fee7e113-666d-4114-9fcb-bcd3046479f3-2630-2.c000.snappy.parquet\n",
      "Mean Pickup Latitude: 40.67717425918579, Mean Pickup Longitude: -73.80773597335815\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from azureml.opendatasets import NycTlcGreen\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "green_taxi_df = pd.DataFrame([])\n",
    "\n",
    "# Define the start and end dates\n",
    "start = datetime.strptime(\"1/1/2016\", \"%m/%d/%Y\")\n",
    "end = datetime.strptime(\"1/31/2016\", \"%m/%d/%Y\")\n",
    "\n",
    "# Loop through the specified range of months and append data\n",
    "for sample_month in range(2):\n",
    "    temp_df_green = NycTlcGreen(\n",
    "        start + relativedelta(months=sample_month),\n",
    "        end + relativedelta(months=sample_month)\n",
    "    ).to_pandas_dataframe()\n",
    "    green_taxi_df = pd.concat([green_taxi_df, temp_df_green.sample(2000)], ignore_index=True)\n",
    "\n",
    "# Get raw column names\n",
    "raw_columns = list(green_taxi_df.columns)\n",
    "\n",
    "# Get descriptive statistics\n",
    "info = green_taxi_df.describe()\n",
    "mean_pickup_latitude = info['pickupLatitude']['mean']\n",
    "mean_pickup_longitude = info['pickupLongitude']['mean']\n",
    "\n",
    "# Drop rows where all of the specified columns have NaN values\n",
    "green_taxi_df = green_taxi_df.dropna(how='all', subset=['lpepPickupDatetime', 'pickupLatitude', 'pickupLongitude'])\n",
    "\n",
    "# Output the DataFrame\n",
    "green_taxi_df\n",
    "\n",
    "# Print mean values for pickup latitude and longitude\n",
    "print(f\"Mean Pickup Latitude: {mean_pickup_latitude}, Mean Pickup Longitude: {mean_pickup_longitude}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8395e93e-1f12-4305-a418-34d35cc913d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'infer_column_types': 'False', 'activity': 'download'}\n",
      "{'infer_column_types': 'False', 'activity': 'download', 'activityApp': 'FileDataset'}\n",
      "[Info] read from /var/folders/m1/v2p5dlc135x8ctp72qfss6200000gn/T/tmpa5v9gop6/https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/green/puYear=2016/puMonth=1/part-00119-tid-4753095944193949832-fee7e113-666d-4114-9fcb-bcd3046479f3-2689-1.c000.snappy.parquet\n",
      "{'infer_column_types': 'False', 'activity': 'download'}\n",
      "{'infer_column_types': 'False', 'activity': 'download', 'activityApp': 'FileDataset'}\n",
      "[Info] read from /var/folders/m1/v2p5dlc135x8ctp72qfss6200000gn/T/tmpk8m4ur7p/https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/green/puYear=2016/puMonth=2/part-00060-tid-4753095944193949832-fee7e113-666d-4114-9fcb-bcd3046479f3-2630-2.c000.snappy.parquet\n",
      "Average Pickup Latitude: 40.675747022628784, Average Pickup Longitude: -73.80753383255005\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from azureml.opendatasets import NycTlcGreen\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "green_taxi_df = pd.DataFrame([])\n",
    "\n",
    "# Define the start and end dates\n",
    "start = datetime.strptime(\"1/1/2016\", \"%m/%d/%Y\")\n",
    "end = datetime.strptime(\"1/31/2016\", \"%m/%d/%Y\")\n",
    "\n",
    "# Loop through the specified range of months and append data\n",
    "for sample_month in range(2):\n",
    "    temp_df_green = NycTlcGreen(\n",
    "        start + relativedelta(months=sample_month),\n",
    "        end + relativedelta(months=sample_month)\n",
    "    ).to_pandas_dataframe()\n",
    "    green_taxi_df = pd.concat([green_taxi_df, temp_df_green.sample(2000)], ignore_index=True)\n",
    "\n",
    "# Get raw column names\n",
    "raw_columns = list(green_taxi_df.columns)\n",
    "\n",
    "# Get descriptive statistics\n",
    "info = green_taxi_df.describe()\n",
    "average_pickup_latitude = info['pickupLatitude']['mean']\n",
    "average_pickup_longitude = info['pickupLongitude']['mean']\n",
    "\n",
    "# Drop rows where all of the specified columns have NaN values\n",
    "green_taxi_df = green_taxi_df.dropna(how='all', subset=['lpepPickupDatetime', 'pickupLatitude', 'pickupLongitude'])\n",
    "\n",
    "# Output the DataFrame\n",
    "green_taxi_df\n",
    "\n",
    "# Print average values for pickup latitude and longitude\n",
    "print(f\"Average Pickup Latitude: {average_pickup_latitude}, Average Pickup Longitude: {average_pickup_longitude}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79190612-51ca-4bae-b503-15c3a9445764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'infer_column_types': 'False', 'activity': 'download'}\n",
      "{'infer_column_types': 'False', 'activity': 'download', 'activityApp': 'FileDataset'}\n",
      "[Info] read from C:\\Users\\Megan\\AppData\\Local\\Temp\\tmpwvmd73a0\\https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/green/puYear=2018/puMonth=1/part-00036-tid-4753095944193949832-fee7e113-666d-4114-9fcb-bcd3046479f3-2606-1.c000.snappy.parquet\n",
      "Total number of pickups from January 1, 2016, to January 31, 2016: 766844\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendorID</th>\n",
       "      <th>lpepPickupDatetime</th>\n",
       "      <th>lpepDropoffDatetime</th>\n",
       "      <th>passengerCount</th>\n",
       "      <th>tripDistance</th>\n",
       "      <th>puLocationId</th>\n",
       "      <th>doLocationId</th>\n",
       "      <th>pickupLongitude</th>\n",
       "      <th>pickupLatitude</th>\n",
       "      <th>dropoffLongitude</th>\n",
       "      <th>...</th>\n",
       "      <th>paymentType</th>\n",
       "      <th>fareAmount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mtaTax</th>\n",
       "      <th>improvementSurcharge</th>\n",
       "      <th>tipAmount</th>\n",
       "      <th>tollsAmount</th>\n",
       "      <th>ehailFee</th>\n",
       "      <th>totalAmount</th>\n",
       "      <th>tripType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-07 19:42:46</td>\n",
       "      <td>2018-01-07 19:48:12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.77</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.56</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-08 10:48:34</td>\n",
       "      <td>2018-01-08 11:09:09</td>\n",
       "      <td>1</td>\n",
       "      <td>2.34</td>\n",
       "      <td>74</td>\n",
       "      <td>236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.76</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-12 19:06:16</td>\n",
       "      <td>2018-01-12 19:20:40</td>\n",
       "      <td>1</td>\n",
       "      <td>1.54</td>\n",
       "      <td>82</td>\n",
       "      <td>129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-12 19:25:24</td>\n",
       "      <td>2018-01-12 20:05:02</td>\n",
       "      <td>1</td>\n",
       "      <td>6.36</td>\n",
       "      <td>129</td>\n",
       "      <td>161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.80</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-12 19:24:58</td>\n",
       "      <td>2018-01-12 19:39:50</td>\n",
       "      <td>1</td>\n",
       "      <td>1.80</td>\n",
       "      <td>75</td>\n",
       "      <td>152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-12 19:53:19</td>\n",
       "      <td>2018-01-12 20:08:35</td>\n",
       "      <td>1</td>\n",
       "      <td>4.30</td>\n",
       "      <td>247</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.80</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   vendorID  lpepPickupDatetime lpepDropoffDatetime  passengerCount  \\\n",
       "0         2 2018-01-07 19:42:46 2018-01-07 19:48:12               1   \n",
       "1         2 2018-01-08 10:48:34 2018-01-08 11:09:09               1   \n",
       "2         2 2018-01-12 19:06:16 2018-01-12 19:20:40               1   \n",
       "3         2 2018-01-12 19:25:24 2018-01-12 20:05:02               1   \n",
       "4         1 2018-01-12 19:24:58 2018-01-12 19:39:50               1   \n",
       "5         1 2018-01-12 19:53:19 2018-01-12 20:08:35               1   \n",
       "\n",
       "   tripDistance puLocationId doLocationId  pickupLongitude  pickupLatitude  \\\n",
       "0          0.77           42           42              NaN             NaN   \n",
       "1          2.34           74          236              NaN             NaN   \n",
       "2          1.54           82          129              NaN             NaN   \n",
       "3          6.36          129          161              NaN             NaN   \n",
       "4          1.80           75          152              NaN             NaN   \n",
       "5          4.30          247           60              NaN             NaN   \n",
       "\n",
       "   dropoffLongitude  ...  paymentType  fareAmount extra  mtaTax  \\\n",
       "0               NaN  ...            1         5.5   0.0     0.5   \n",
       "1               NaN  ...            1        14.0   0.0     0.5   \n",
       "2               NaN  ...            1        10.0   1.0     0.5   \n",
       "3               NaN  ...            2        27.0   1.0     0.5   \n",
       "4               NaN  ...            2        10.5   1.0     0.5   \n",
       "5               NaN  ...            1        15.0   1.0     0.5   \n",
       "\n",
       "   improvementSurcharge  tipAmount  tollsAmount ehailFee  totalAmount  \\\n",
       "0                   0.3       1.26          0.0      NaN         7.56   \n",
       "1                   0.3       2.96          0.0      NaN        17.76   \n",
       "2                   0.3       2.36          0.0      NaN        14.16   \n",
       "3                   0.3       0.00          0.0      NaN        28.80   \n",
       "4                   0.3       0.00          0.0      NaN        12.30   \n",
       "5                   0.3       0.00          0.0      NaN        16.80   \n",
       "\n",
       "   tripType  \n",
       "0       1.0  \n",
       "1       1.0  \n",
       "2       1.0  \n",
       "3       1.0  \n",
       "4       1.0  \n",
       "5       1.0  \n",
       "\n",
       "[6 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from azureml.opendatasets import NycTlcGreen\n",
    "\n",
    "# Define the start and end dates\n",
    "start = datetime.strptime(\"1/1/2018\", \"%m/%d/%Y\")\n",
    "end = datetime.strptime(\"1/31/2018\", \"%m/%d/%Y\")\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "green_taxi_df = pd.DataFrame([])\n",
    "\n",
    "# Loop through the specified range of months and append data\n",
    "for sample_month in range(1):\n",
    "    temp_df_green = NycTlcGreen(\n",
    "        start + relativedelta(months=sample_month),\n",
    "        end + relativedelta(months=sample_month)\n",
    "    ).to_pandas_dataframe()\n",
    "    green_taxi_df = pd.concat([green_taxi_df, temp_df_green], ignore_index=True)\n",
    "\n",
    "# Get raw column names\n",
    "raw_columns = list(green_taxi_df.columns)\n",
    "\n",
    "# Get the total number of pickups\n",
    "total_pickups = green_taxi_df.shape[0]\n",
    "\n",
    "# Drop rows where all of the specified columns have NaN values\n",
    "green_taxi_df = green_taxi_df.dropna(how='all', subset=['lpepPickupDatetime', 'pickupLatitude', 'pickupLongitude'])\n",
    "\n",
    "# Output the total number of pickups\n",
    "print(f\"Total number of pickups from January 1, 2016, to January 31, 2016: {total_pickups}\")\n",
    "\n",
    "# Display the DataFrame\n",
    "green_taxi_df.head(6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0df3ba64-86a2-48ae-b77a-411b8b74413c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'infer_column_types': 'False', 'activity': 'download'}\n",
      "{'infer_column_types': 'False', 'activity': 'download', 'activityApp': 'FileDataset'}\n",
      "[Info] read from C:\\Users\\Megan\\AppData\\Local\\Temp\\tmppgz34hhk\\https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/green/puYear=2016/puMonth=1/part-00119-tid-4753095944193949832-fee7e113-666d-4114-9fcb-bcd3046479f3-2689-1.c000.snappy.parquet\n",
      "Total number of pickups from January 1, 2016, to January 31, 2016: 1,393,001\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from azureml.opendatasets import NycTlcGreen\n",
    "\n",
    "# Define the start and end dates\n",
    "start = datetime.strptime(\"1/1/2016\", \"%m/%d/%Y\")\n",
    "end = datetime.strptime(\"1/31/2016\", \"%m/%d/%Y\")\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "green_taxi_df = pd.DataFrame([])\n",
    "\n",
    "# Load data for the specified date range\n",
    "temp_df_green = NycTlcGreen(start, end).to_pandas_dataframe()\n",
    "green_taxi_df = pd.concat([green_taxi_df, temp_df_green], ignore_index=True)\n",
    "\n",
    "# Get the total number of pickups\n",
    "total_pickups = green_taxi_df.shape[0]\n",
    "\n",
    "# Output the total number of pickups with commas\n",
    "print(f\"Total number of pickups from January 1, 2016, to January 31, 2016: {total_pickups:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c1848e-7c34-4652-b63c-f7736467d5b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
